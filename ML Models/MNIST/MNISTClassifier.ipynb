{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network model to perform classification of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Import all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import coremltools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Set random state which is about to be used in a notebook and some numpy, matpotlib settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 5760x5760 with 0 Axes>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 5760x5760 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "plt.figure(figsize=(80,80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Let's load MNIST data and split it into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Let's look at the data we are going to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
    "    plt.title(y_train[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Let's process our data to prepare it for training and validation as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows, image_cols = 28, 28\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, image_rows, image_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, image_rows, image_cols)\n",
    "    input_shape = (1, image_rows, image_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], image_rows, image_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], image_rows, image_cols, 1)\n",
    "    input_shape = (image_rows, image_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32') / 5\n",
    "X_test = X_test.astype('float32') / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Encode Categorical Features with Ohe Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_categories)\n",
    "y_test = np_utils.to_categorical(y_test, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Declare, tune and compile the Neural Network Architecture (VGG-like ConvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Perform training on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.3014 - acc: 0.9098 - val_loss: 0.0482 - val_acc: 0.9843\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0848 - acc: 0.9742 - val_loss: 0.0291 - val_acc: 0.9907\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0607 - acc: 0.9808 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0509 - acc: 0.9848 - val_loss: 0.0252 - val_acc: 0.9916\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0418 - acc: 0.9872 - val_loss: 0.0213 - val_acc: 0.9929\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0364 - acc: 0.9887 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0318 - acc: 0.9902 - val_loss: 0.0190 - val_acc: 0.9939\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0197 - val_acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4a9c8240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epoch = 8\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', model.evaluate(X_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **So we've got a really decent accuracy. The model is doing great!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Convert the model into MLModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_5_input, <keras.engine.input_layer.InputLayer object at 0x1a4a9daac8>\n",
      "1 : conv2d_5, <keras.layers.convolutional.Conv2D object at 0x1a4a9da8d0>\n",
      "2 : conv2d_5__activation__, <keras.layers.core.Activation object at 0x1a4b363860>\n",
      "3 : conv2d_6, <keras.layers.convolutional.Conv2D object at 0x1a4a9da940>\n",
      "4 : conv2d_6__activation__, <keras.layers.core.Activation object at 0x1a4b363208>\n",
      "5 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x1a4a9d3a58>\n",
      "6 : conv2d_7, <keras.layers.convolutional.Conv2D object at 0x1a4a9dab00>\n",
      "7 : conv2d_7__activation__, <keras.layers.core.Activation object at 0x1a4b363c50>\n",
      "8 : conv2d_8, <keras.layers.convolutional.Conv2D object at 0x1a4a9d3fd0>\n",
      "9 : conv2d_8__activation__, <keras.layers.core.Activation object at 0x1a3f3bc320>\n",
      "10 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x1a4aa69588>\n",
      "11 : flatten_2, <keras.layers.core.Flatten object at 0x1a4aa69780>\n",
      "12 : dense_3, <keras.layers.core.Dense object at 0x1a4aa695c0>\n",
      "13 : dense_3__activation__, <keras.layers.core.Activation object at 0x1a3f3bcb00>\n",
      "14 : dense_4, <keras.layers.core.Dense object at 0x1a4aad5978>\n",
      "15 : dense_4__activation__, <keras.layers.core.Activation object at 0x1a4b373400>\n"
     ]
    }
   ],
   "source": [
    "output_labels = [\n",
    "    '0',\n",
    "    '1', \n",
    "    '2', \n",
    "    '3', \n",
    "    '4', \n",
    "    '5',\n",
    "    '6',\n",
    "    '7',\n",
    "    '8',\n",
    "    '9'\n",
    "]\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert(model,\n",
    "                                                   input_names='image',\n",
    "                                                   image_input_names='image',\n",
    "                                                   output_names='prediction',\n",
    "                                                   class_labels=output_labels)\n",
    "\n",
    "coreml_model.author = 'Alex Milogradsky'\n",
    "coreml_model.short_description = 'Simple Neural Network model to perform classification of handwritten digits'\n",
    "coreml_model.input_description['image'] = 'Image of a handwritten digit'\n",
    "coreml_model.output_description['prediction'] = 'Predicted digit'\n",
    "coreml_model.save('MNISTClassifier2.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
